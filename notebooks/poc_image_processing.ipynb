{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/Users/odunayoogundepo/Downloads/test_images_karanta/pdf/dictionary/dictionaryoftebe00elliuoft_page_292.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "\n",
    "def load_pdf_as_images(pdf_path, page_range=1):\n",
    "    \"\"\"\n",
    "    Load PDF pages as images using pypdf and pdf2image.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): Path to the PDF file\n",
    "        page_range (tuple): (start, end) page numbers (1-indexed), None for all pages\n",
    "\n",
    "    Returns:\n",
    "        list: List of PIL Images, one per page\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # First, get PDF info using pypdf\n",
    "        reader = PdfReader(pdf_path)\n",
    "        total_pages = len(reader.pages)\n",
    "\n",
    "        print(f\"PDF has {total_pages} pages\")\n",
    "\n",
    "        # Determine page range\n",
    "        if page_range:\n",
    "            start_page = 1\n",
    "            end_page = 1\n",
    "            first_page = start_page\n",
    "            last_page = end_page\n",
    "        else:\n",
    "            first_page = 1\n",
    "            last_page = total_pages\n",
    "\n",
    "        # Convert PDF pages to images using pdf2image\n",
    "        images = convert_from_path(\n",
    "            pdf_path, dpi=500, first_page=first_page, last_page=last_page, fmt=\"PNG\"\n",
    "        )\n",
    "\n",
    "        print(f\"Loaded {len(images)} pages as images\")\n",
    "        return images\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading PDF {pdf_path}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "images = load_pdf_as_images(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageEnhance\n",
    "\n",
    "\n",
    "def show_image(image, title=\"Image\", figsize=(12, 8)):\n",
    "    \"\"\"\n",
    "    Display an image using matplotlib.\n",
    "\n",
    "    Args:\n",
    "        image: PIL Image or numpy array\n",
    "        title (str): Title for the plot\n",
    "        figsize (tuple): Figure size (width, height)\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    if isinstance(image, Image.Image):\n",
    "        plt.imshow(image, cmap=\"gray\" if image.mode == \"L\" else None)\n",
    "    else:\n",
    "        plt.imshow(image, cmap=\"gray\" if len(image.shape) == 2 else None)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "show_image(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def enhance_document_quality(image, method=\"adaptive\"):\n",
    "    \"\"\"\n",
    "    Improve document quality by cleaning background and sharpening text.\n",
    "\n",
    "    Args:\n",
    "        image: PIL Image\n",
    "        method (str): 'adaptive', 'otsu', 'enhanced', or 'aggressive'\n",
    "\n",
    "    Returns:\n",
    "        PIL Image: Processed image\n",
    "    \"\"\"\n",
    "\n",
    "    # image = Image.fromarray(cv2.cvtColor(np.array(image), cv2.COLOR_RGB2GRAY))\n",
    "\n",
    "    # Convert PIL to OpenCV format\n",
    "    if image.mode != \"L\":\n",
    "        image = image.convert(\"L\")\n",
    "    img_array = np.array(image)\n",
    "\n",
    "    if method == \"adaptive\":\n",
    "        return _adaptive_threshold_method(img_array)\n",
    "    elif method == \"otsu\":\n",
    "        return _otsu_method(img_array)\n",
    "    elif method == \"enhanced\":\n",
    "        return _enhanced_method(img_array)\n",
    "    elif method == \"aggressive\":\n",
    "        return _aggressive_cleaning_method(img_array)\n",
    "    elif method == \"stackoverflow\":\n",
    "        return stackoverflow(img_array)\n",
    "    else:\n",
    "        return Image.fromarray(img_array)\n",
    "\n",
    "\n",
    "def stackoverflow(img_array):\n",
    "    dilated_img = cv2.dilate(img_array, np.ones((7, 7), np.uint8))\n",
    "    bg_img = cv2.medianBlur(dilated_img, 10)\n",
    "    diff_img = 255 - cv2.absdiff(img_array, bg_img)\n",
    "    norm_img = cv2.normalize(\n",
    "        diff_img, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8UC1\n",
    "    )\n",
    "\n",
    "    # Threshold using Otsu's\n",
    "    work_img = cv2.threshold(norm_img, 0, 255, cv2.THRESH_OTSU)[1]\n",
    "\n",
    "    return Image.fromarray(work_img)\n",
    "\n",
    "\n",
    "def _adaptive_threshold_method(img_array):\n",
    "    \"\"\"Adaptive thresholding method - good for varying lighting.\"\"\"\n",
    "    # Denoise\n",
    "    denoised = cv2.bilateralFilter(img_array, 9, 75, 75)\n",
    "\n",
    "    # Adaptive threshold\n",
    "    denoised = cv2.adaptiveThreshold(\n",
    "        denoised, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2\n",
    "    )\n",
    "\n",
    "    return Image.fromarray(denoised)\n",
    "\n",
    "\n",
    "def _otsu_method(img_array):\n",
    "    \"\"\"Otsu's method - automatically finds optimal threshold.\"\"\"\n",
    "    # Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(img_array, (5, 5), 0)\n",
    "\n",
    "    # Otsu's thresholding\n",
    "    _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    return Image.fromarray(thresh)\n",
    "\n",
    "\n",
    "def _enhanced_method(img_array):\n",
    "    \"\"\"Enhanced method using PIL for more control.\"\"\"\n",
    "    img = Image.fromarray(img_array)\n",
    "\n",
    "    # Enhance contrast\n",
    "    enhancer = ImageEnhance.Contrast(img)\n",
    "    img = enhancer.enhance(1.5)\n",
    "\n",
    "    # Enhance sharpness\n",
    "    enhancer = ImageEnhance.Sharpness(img)\n",
    "    img = enhancer.enhance(2.0)\n",
    "\n",
    "    # Convert back to array for thresholding\n",
    "    img_array = np.array(img)\n",
    "\n",
    "    # Apply adaptive threshold\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        img_array, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 15, 8\n",
    "    )\n",
    "\n",
    "    return Image.fromarray(thresh)\n",
    "\n",
    "\n",
    "def _aggressive_cleaning_method(img_array):\n",
    "    \"\"\"Aggressive cleaning for very noisy documents.\"\"\"\n",
    "    # Heavy denoising\n",
    "    denoised = cv2.bilateralFilter(img_array, 15, 100, 100)\n",
    "\n",
    "    # Morphological operations to remove noise\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "    cleaned = cv2.morphologyEx(denoised, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # Adaptive threshold with larger neighborhood\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        cleaned, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 21, 10\n",
    "    )\n",
    "\n",
    "    # Final morphological closing to connect text\n",
    "    kernel2 = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 1))\n",
    "    final = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel2)\n",
    "\n",
    "    return Image.fromarray(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(enhance_document_quality(images[0], method=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "\n",
    "def rotate_image(image: np.ndarray, angle: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Rotate image by specified angle (90, 180, 270 degrees).\n",
    "    \"\"\"\n",
    "    if angle == 90:\n",
    "        return cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n",
    "    elif angle == 180:\n",
    "        return cv2.rotate(image, cv2.ROTATE_180)\n",
    "    elif angle == 270:\n",
    "        return cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    else:\n",
    "        return image\n",
    "\n",
    "\n",
    "def detect_orientation_text_lines(image: np.ndarray) -> Optional[int]:\n",
    "    \"\"\"\n",
    "    Detect text orientation by analyzing horizontal/vertical line patterns.\n",
    "    \"\"\"\n",
    "    # Convert to grayscale\n",
    "    # gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply binary threshold\n",
    "    _, binary = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Invert if necessary (text should be black on white)\n",
    "    if np.mean(binary) < 127:\n",
    "        binary = cv2.bitwise_not(binary)\n",
    "\n",
    "    # Detect horizontal and vertical lines\n",
    "    horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (25, 1))\n",
    "    vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 25))\n",
    "\n",
    "    horizontal_lines = cv2.morphologyEx(binary, cv2.MORPH_OPEN, horizontal_kernel)\n",
    "    vertical_lines = cv2.morphologyEx(binary, cv2.MORPH_OPEN, vertical_kernel)\n",
    "\n",
    "    # Count line pixels\n",
    "    h_pixels = np.sum(horizontal_lines > 0)\n",
    "    v_pixels = np.sum(vertical_lines > 0)\n",
    "\n",
    "    # Determine orientation based on line dominance\n",
    "    if h_pixels > v_pixels * 1.5:  # Strong horizontal dominance\n",
    "        return 0  # No rotation needed\n",
    "    elif v_pixels > h_pixels * 1.5:  # Strong vertical dominance\n",
    "        return 270  # Rotate 270° (or -90°)\n",
    "\n",
    "    # If unclear, try rotated versions\n",
    "    rotations_to_test = [90, 180, 270]\n",
    "    line_scores = {0: h_pixels / (v_pixels + 1)}  # Original orientation score\n",
    "\n",
    "    for angle in rotations_to_test:\n",
    "        rotated = rotate_image(binary, angle)\n",
    "\n",
    "        h_lines_rot = cv2.morphologyEx(rotated, cv2.MORPH_OPEN, horizontal_kernel)\n",
    "        v_lines_rot = cv2.morphologyEx(rotated, cv2.MORPH_OPEN, vertical_kernel)\n",
    "\n",
    "        h_pix_rot = np.sum(h_lines_rot > 0)\n",
    "        v_pix_rot = np.sum(v_lines_rot > 0)\n",
    "\n",
    "        score = h_pix_rot / (v_pix_rot + 1)\n",
    "        correction_angle = (360 - angle) % 360\n",
    "        line_scores[correction_angle] = score\n",
    "\n",
    "    # Return the correction angle that gives the best horizontal line score\n",
    "    best_correction = max(line_scores.items(), key=lambda x: x[1])[0]\n",
    "    return best_correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "input_path = \"/Users/odunayoogundepo/Downloads/test_images_karanta/pdf/newspaper/\"\n",
    "\n",
    "all_files = [\n",
    "    os.path.join(input_path, f) for f in os.listdir(input_path) if f.endswith(\".pdf\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "random_image = \"/Users/odunayoogundepo/Downloads/test_images_karanta/pdf/newspaper/newspaper 16_page_20.pdf\"  # random.choice(all_files)\n",
    "image = load_pdf_as_images(random_image)\n",
    "\n",
    "print(detect_orientation_text_lines(np.array(image)))\n",
    "\n",
    "show_image(image[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_orientation_text_lines(np.array(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newspaper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
